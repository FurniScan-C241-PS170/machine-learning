{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J65lLY3KAGIp",
        "outputId": "d5748432-e787-4507-c738-34a95907f895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/NewDatasetsForKeras.zip\n",
            "   creating: validation/\n",
            "   creating: validation/kursi01/\n",
            "  inflating: validation/kursi01/kursi01.jpg  \n",
            "  inflating: validation/kursi01/kursi02.jpg  \n",
            "  inflating: validation/kursi01/kursi03.jpg  \n",
            "  inflating: validation/kursi01/kursi04.jpg  \n",
            "  inflating: validation/kursi01/kursi76.jpg  \n",
            "  inflating: validation/kursi01/kursi77.jpg  \n",
            "  inflating: validation/kursi01/kursi78.jpg  \n",
            "  inflating: validation/kursi01/kursi79.jpg  \n",
            "  inflating: validation/kursi01/kursi80.jpg  \n",
            "  inflating: validation/kursi01/kursi81.jpg  \n",
            "   creating: validation/kursi02/\n",
            "  inflating: validation/kursi02/kursi05.jpg  \n",
            "  inflating: validation/kursi02/kursi06.jpg  \n",
            "  inflating: validation/kursi02/kursi07.jpg  \n",
            "  inflating: validation/kursi02/kursi08.jpg  \n",
            "   creating: validation/kursi03/\n",
            "  inflating: validation/kursi03/kursi09.jpg  \n",
            "  inflating: validation/kursi03/kursi10.jpg  \n",
            "  inflating: validation/kursi03/kursi11.jpg  \n",
            "  inflating: validation/kursi03/kursi12.jpg  \n",
            "  inflating: validation/kursi03/kursi13.jpg  \n",
            "  inflating: validation/kursi03/kursi14.jpg  \n",
            "   creating: validation/kursi04/\n",
            "  inflating: validation/kursi04/kursi15.JPG  \n",
            "  inflating: validation/kursi04/kursi16.JPG  \n",
            "  inflating: validation/kursi04/kursi17.JPG  \n",
            "  inflating: validation/kursi04/kursi18.JPG  \n",
            "  inflating: validation/kursi04/kursi19.JPG  \n",
            "  inflating: validation/kursi04/kursi20.JPG  \n",
            "  inflating: validation/kursi04/kursi21.jpg  \n",
            "  inflating: validation/kursi04/kursi22.jpg  \n",
            "   creating: validation/kursi05/\n",
            "  inflating: validation/kursi05/kursi21.jpg  \n",
            "  inflating: validation/kursi05/kursi22.jpg  \n",
            "  inflating: validation/kursi05/kursi23.jpg  \n",
            "  inflating: validation/kursi05/kursi24.jpg  \n",
            "  inflating: validation/kursi05/kursi25.jpg  \n",
            "  inflating: validation/kursi05/kursi26.jpg  \n",
            "  inflating: validation/kursi05/kursi27.jpg  \n",
            "  inflating: validation/kursi05/kursi28.jpg  \n",
            "  inflating: validation/kursi05/kursi29.jpg  \n",
            "  inflating: validation/kursi05/kursi30.jpg  \n",
            "   creating: validation/kursi06/\n",
            "  inflating: validation/kursi06/kursi28.jpg  \n",
            "  inflating: validation/kursi06/kursi29.jpg  \n",
            "  inflating: validation/kursi06/kursi30.jpg  \n",
            "  inflating: validation/kursi06/kursi31.jpg  \n",
            "  inflating: validation/kursi06/kursi32.jpg  \n",
            "  inflating: validation/kursi06/kursi33.jpg  \n",
            "  inflating: validation/kursi06/kursi34.jpg  \n",
            "  inflating: validation/kursi06/kursi35.jpg  \n",
            "  inflating: validation/kursi06/kursi36.jpg  \n",
            "  inflating: validation/kursi06/kursi37.jpg  \n",
            "   creating: validation/kursi07/\n",
            "  inflating: validation/kursi07/kursi35.jpg  \n",
            "  inflating: validation/kursi07/kursi36.jpg  \n",
            "  inflating: validation/kursi07/kursi37.jpg  \n",
            "  inflating: validation/kursi07/kursi38.jpg  \n",
            "  inflating: validation/kursi07/kursi39.jpg  \n",
            "  inflating: validation/kursi07/kursi40.jpg  \n",
            "  inflating: validation/kursi07/kursi41.jpg  \n",
            "  inflating: validation/kursi07/kursi42.jpg  \n",
            "  inflating: validation/kursi07/kursi43.jpg  \n",
            "  inflating: validation/kursi07/kursi44.jpg  \n",
            "   creating: validation/kursi08/\n",
            "  inflating: validation/kursi08/kursi42.jpg  \n",
            "  inflating: validation/kursi08/kursi43.jpg  \n",
            "  inflating: validation/kursi08/kursi44.jpg  \n",
            "  inflating: validation/kursi08/kursi45.jpg  \n",
            "  inflating: validation/kursi08/kursi46.jpg  \n",
            "  inflating: validation/kursi08/kursi47.jpg  \n",
            "  inflating: validation/kursi08/kursi48.jpg  \n",
            "  inflating: validation/kursi08/kursi49.jpg  \n",
            "  inflating: validation/kursi08/kursi50.jpg  \n",
            "  inflating: validation/kursi08/kursi51.jpg  \n",
            "  inflating: validation/kursi08/kursi52.jpg  \n",
            "  inflating: validation/kursi08/kursi53.jpg  \n",
            "   creating: validation/kursi09/\n",
            "  inflating: validation/kursi09/kursi50.jpg  \n",
            "  inflating: validation/kursi09/kursi51.jpg  \n",
            "  inflating: validation/kursi09/kursi52.jpg  \n",
            "  inflating: validation/kursi09/kursi53.jpg  \n",
            "  inflating: validation/kursi09/kursi54.jpg  \n",
            "  inflating: validation/kursi09/kursi55.jpg  \n",
            "  inflating: validation/kursi09/kursi56.jpg  \n",
            "  inflating: validation/kursi09/kursi57.jpg  \n",
            "  inflating: validation/kursi09/kursi58.jpg  \n",
            "   creating: validation/kursi10/\n",
            "  inflating: validation/kursi10/kursi57.jpg  \n",
            "  inflating: validation/kursi10/kursi58.jpg  \n",
            "  inflating: validation/kursi10/kursi59.jpg  \n",
            "  inflating: validation/kursi10/kursi60.jpg  \n",
            "  inflating: validation/kursi10/kursi61.jpg  \n",
            "  inflating: validation/kursi10/kursi62.jpg  \n",
            "  inflating: validation/kursi10/kursi63.jpg  \n",
            "  inflating: validation/kursi10/kursi64.jpg  \n",
            "  inflating: validation/kursi10/kursi65.jpg  \n",
            "   creating: validation/kursi11/\n",
            "  inflating: validation/kursi11/kursi64.jpg  \n",
            "  inflating: validation/kursi11/kursi65.jpg  \n",
            "  inflating: validation/kursi11/kursi66.jpg  \n",
            "  inflating: validation/kursi11/kursi67.jpg  \n",
            "  inflating: validation/kursi11/kursi68.jpg  \n",
            "  inflating: validation/kursi11/kursi69.jpg  \n",
            "  inflating: validation/kursi11/kursi70.jpg  \n",
            "  inflating: validation/kursi11/kursi71.jpg  \n",
            "  inflating: validation/kursi11/kursi72.jpg  \n",
            "  inflating: validation/kursi11/kursi73.jpg  \n",
            "  inflating: validation/kursi11/kursi74.jpg  \n",
            "   creating: validation/kursi12/\n",
            "  inflating: validation/kursi12/kursi71.jpg  \n",
            "  inflating: validation/kursi12/kursi72.jpg  \n",
            "  inflating: validation/kursi12/kursi73.jpg  \n",
            "  inflating: validation/kursi12/kursi74.jpg  \n",
            "  inflating: validation/kursi12/kursi75.jpg  \n",
            "  inflating: validation/kursi12/kursi76.jpg  \n",
            "   creating: validation/meja01/\n",
            "  inflating: validation/meja01/meja01.JPG  \n",
            "  inflating: validation/meja01/meja02.JPG  \n",
            "  inflating: validation/meja01/meja03.JPG  \n",
            "  inflating: validation/meja01/meja04.JPG  \n",
            "  inflating: validation/meja01/meja05.JPG  \n",
            "  inflating: validation/meja01/meja06.JPG  \n",
            "  inflating: validation/meja01/meja07.JPG  \n",
            "  inflating: validation/meja01/meja08.JPG  \n",
            "  inflating: validation/meja01/meja09.JPG  \n",
            "   creating: validation/sofa01/\n",
            "  inflating: validation/sofa01/sofa01.jpg  \n",
            "  inflating: validation/sofa01/sofa02.jpg  \n",
            "  inflating: validation/sofa01/sofa03.jpg  \n",
            "  inflating: validation/sofa01/sofa04.jpg  \n",
            "  inflating: validation/sofa01/sofa05.jpg  \n",
            "  inflating: validation/sofa01/sofa06.jpg  \n",
            "  inflating: validation/sofa01/sofa07.jpg  \n",
            "  inflating: validation/sofa01/sofa08.jpg  \n",
            "   creating: train/\n",
            "   creating: train/kursi01/\n",
            "  inflating: train/kursi01/kursi01.jpg  \n",
            "  inflating: train/kursi01/kursi02.jpg  \n",
            "  inflating: train/kursi01/kursi03.jpg  \n",
            "  inflating: train/kursi01/kursi04.jpg  \n",
            "  inflating: train/kursi01/kursi76.jpg  \n",
            "  inflating: train/kursi01/kursi77.jpg  \n",
            "  inflating: train/kursi01/kursi78.jpg  \n",
            "  inflating: train/kursi01/kursi79.jpg  \n",
            "  inflating: train/kursi01/kursi80.jpg  \n",
            "  inflating: train/kursi01/kursi81.jpg  \n",
            "   creating: train/kursi02/\n",
            "  inflating: train/kursi02/kursi05.jpg  \n",
            "  inflating: train/kursi02/kursi06.jpg  \n",
            "  inflating: train/kursi02/kursi07.jpg  \n",
            "  inflating: train/kursi02/kursi08.jpg  \n",
            "   creating: train/kursi03/\n",
            "  inflating: train/kursi03/kursi09.jpg  \n",
            "  inflating: train/kursi03/kursi10.jpg  \n",
            "  inflating: train/kursi03/kursi11.jpg  \n",
            "  inflating: train/kursi03/kursi12.jpg  \n",
            "  inflating: train/kursi03/kursi13.jpg  \n",
            "  inflating: train/kursi03/kursi14.jpg  \n",
            "   creating: train/kursi04/\n",
            "  inflating: train/kursi04/kursi15.JPG  \n",
            "  inflating: train/kursi04/kursi16.JPG  \n",
            "  inflating: train/kursi04/kursi17.JPG  \n",
            "  inflating: train/kursi04/kursi18.JPG  \n",
            "  inflating: train/kursi04/kursi19.JPG  \n",
            "  inflating: train/kursi04/kursi20.JPG  \n",
            "  inflating: train/kursi04/kursi21.jpg  \n",
            "  inflating: train/kursi04/kursi22.jpg  \n",
            "   creating: train/kursi05/\n",
            "  inflating: train/kursi05/kursi21.jpg  \n",
            "  inflating: train/kursi05/kursi22.jpg  \n",
            "  inflating: train/kursi05/kursi23.jpg  \n",
            "  inflating: train/kursi05/kursi24.jpg  \n",
            "  inflating: train/kursi05/kursi25.jpg  \n",
            "  inflating: train/kursi05/kursi26.jpg  \n",
            "  inflating: train/kursi05/kursi27.jpg  \n",
            "  inflating: train/kursi05/kursi28.jpg  \n",
            "  inflating: train/kursi05/kursi29.jpg  \n",
            "  inflating: train/kursi05/kursi30.jpg  \n",
            "   creating: train/kursi06/\n",
            "  inflating: train/kursi06/kursi28.jpg  \n",
            "  inflating: train/kursi06/kursi29.jpg  \n",
            "  inflating: train/kursi06/kursi30.jpg  \n",
            "  inflating: train/kursi06/kursi31.jpg  \n",
            "  inflating: train/kursi06/kursi32.jpg  \n",
            "  inflating: train/kursi06/kursi33.jpg  \n",
            "  inflating: train/kursi06/kursi34.jpg  \n",
            "  inflating: train/kursi06/kursi35.jpg  \n",
            "  inflating: train/kursi06/kursi36.jpg  \n",
            "  inflating: train/kursi06/kursi37.jpg  \n",
            "   creating: train/kursi07/\n",
            "  inflating: train/kursi07/kursi35.jpg  \n",
            "  inflating: train/kursi07/kursi36.jpg  \n",
            "  inflating: train/kursi07/kursi37.jpg  \n",
            "  inflating: train/kursi07/kursi38.jpg  \n",
            "  inflating: train/kursi07/kursi39.jpg  \n",
            "  inflating: train/kursi07/kursi40.jpg  \n",
            "  inflating: train/kursi07/kursi41.jpg  \n",
            "  inflating: train/kursi07/kursi42.jpg  \n",
            "  inflating: train/kursi07/kursi43.jpg  \n",
            "  inflating: train/kursi07/kursi44.jpg  \n",
            "   creating: train/kursi08/\n",
            "  inflating: train/kursi08/kursi42.jpg  \n",
            "  inflating: train/kursi08/kursi43.jpg  \n",
            "  inflating: train/kursi08/kursi44.jpg  \n",
            "  inflating: train/kursi08/kursi45.jpg  \n",
            "  inflating: train/kursi08/kursi46.jpg  \n",
            "  inflating: train/kursi08/kursi47.jpg  \n",
            "  inflating: train/kursi08/kursi48.jpg  \n",
            "  inflating: train/kursi08/kursi49.jpg  \n",
            "  inflating: train/kursi08/kursi50.jpg  \n",
            "  inflating: train/kursi08/kursi51.jpg  \n",
            "  inflating: train/kursi08/kursi52.jpg  \n",
            "  inflating: train/kursi08/kursi53.jpg  \n",
            "   creating: train/kursi09/\n",
            "  inflating: train/kursi09/kursi50.jpg  \n",
            "  inflating: train/kursi09/kursi51.jpg  \n",
            "  inflating: train/kursi09/kursi52.jpg  \n",
            "  inflating: train/kursi09/kursi53.jpg  \n",
            "  inflating: train/kursi09/kursi54.jpg  \n",
            "  inflating: train/kursi09/kursi55.jpg  \n",
            "  inflating: train/kursi09/kursi56.jpg  \n",
            "  inflating: train/kursi09/kursi57.jpg  \n",
            "  inflating: train/kursi09/kursi58.jpg  \n",
            "   creating: train/kursi10/\n",
            "  inflating: train/kursi10/kursi57.jpg  \n",
            "  inflating: train/kursi10/kursi58.jpg  \n",
            "  inflating: train/kursi10/kursi59.jpg  \n",
            "  inflating: train/kursi10/kursi60.jpg  \n",
            "  inflating: train/kursi10/kursi61.jpg  \n",
            "  inflating: train/kursi10/kursi62.jpg  \n",
            "  inflating: train/kursi10/kursi63.jpg  \n",
            "  inflating: train/kursi10/kursi64.jpg  \n",
            "  inflating: train/kursi10/kursi65.jpg  \n",
            "   creating: train/kursi11/\n",
            "  inflating: train/kursi11/kursi64.jpg  \n",
            "  inflating: train/kursi11/kursi65.jpg  \n",
            "  inflating: train/kursi11/kursi66.jpg  \n",
            "  inflating: train/kursi11/kursi67.jpg  \n",
            "  inflating: train/kursi11/kursi68.jpg  \n",
            "  inflating: train/kursi11/kursi69.jpg  \n",
            "  inflating: train/kursi11/kursi70.jpg  \n",
            "  inflating: train/kursi11/kursi71.jpg  \n",
            "  inflating: train/kursi11/kursi72.jpg  \n",
            "  inflating: train/kursi11/kursi73.jpg  \n",
            "  inflating: train/kursi11/kursi74.jpg  \n",
            "   creating: train/kursi12/\n",
            "  inflating: train/kursi12/kursi71.jpg  \n",
            "  inflating: train/kursi12/kursi72.jpg  \n",
            "  inflating: train/kursi12/kursi73.jpg  \n",
            "  inflating: train/kursi12/kursi74.jpg  \n",
            "  inflating: train/kursi12/kursi75.jpg  \n",
            "  inflating: train/kursi12/kursi76.jpg  \n",
            "   creating: train/meja01/\n",
            "  inflating: train/meja01/meja01.JPG  \n",
            "  inflating: train/meja01/meja02.JPG  \n",
            "  inflating: train/meja01/meja03.JPG  \n",
            "  inflating: train/meja01/meja04.JPG  \n",
            "  inflating: train/meja01/meja05.JPG  \n",
            "  inflating: train/meja01/meja06.JPG  \n",
            "  inflating: train/meja01/meja07.JPG  \n",
            "  inflating: train/meja01/meja08.JPG  \n",
            "  inflating: train/meja01/meja09.JPG  \n",
            "   creating: train/sofa01/\n",
            "  inflating: train/sofa01/sofa01.jpg  \n",
            "  inflating: train/sofa01/sofa02.jpg  \n",
            "  inflating: train/sofa01/sofa03.jpg  \n",
            "  inflating: train/sofa01/sofa04.jpg  \n",
            "  inflating: train/sofa01/sofa05.jpg  \n",
            "  inflating: train/sofa01/sofa06.jpg  \n",
            "  inflating: train/sofa01/sofa07.jpg  \n",
            "  inflating: train/sofa01/sofa08.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/NewDatasetsForKeras.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lemvV9e4Fte",
        "outputId": "a014c27a-15b8-46a9-c02a-e36ce13a129b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 122 images belonging to 14 classes.\n",
            "Found 122 images belonging to 14 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Parameters\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Training data generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Validate data generator\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/train',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    '/validation',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUZXMRbh8znK",
        "outputId": "3f6f54f1-0dfc-47e8-bfed-d2f4d5907f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               12845568  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 14)                7182      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27567438 (105.16 MB)\n",
            "Trainable params: 12852750 (49.03 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "# Load VGG16 model + higher level layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of VGG16 base model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(14, activation='softmax')(x)\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO6lLK6m81A-",
        "outputId": "4fe873fd-e736-45f7-89b2-900a9765d52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "3/3 [==============================] - 13s 792ms/step - loss: 6.0097 - accuracy: 0.0833 - val_loss: 3.3537 - val_accuracy: 0.3750\n",
            "Epoch 2/150\n",
            "3/3 [==============================] - 7s 3s/step - loss: 6.2358 - accuracy: 0.1444 - val_loss: 1.6959 - val_accuracy: 0.6250\n",
            "Epoch 3/150\n",
            "3/3 [==============================] - 2s 673ms/step - loss: 4.3992 - accuracy: 0.2444 - val_loss: 1.1020 - val_accuracy: 0.7292\n",
            "Epoch 4/150\n",
            "3/3 [==============================] - 2s 863ms/step - loss: 2.0714 - accuracy: 0.4375 - val_loss: 0.5652 - val_accuracy: 0.8438\n",
            "Epoch 5/150\n",
            "3/3 [==============================] - 2s 690ms/step - loss: 1.8982 - accuracy: 0.4167 - val_loss: 0.5469 - val_accuracy: 0.8333\n",
            "Epoch 6/150\n",
            "3/3 [==============================] - 2s 714ms/step - loss: 1.4948 - accuracy: 0.5444 - val_loss: 0.5464 - val_accuracy: 0.8229\n",
            "Epoch 7/150\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 1.1253 - accuracy: 0.6222 - val_loss: 0.5666 - val_accuracy: 0.8229\n",
            "Epoch 8/150\n",
            "3/3 [==============================] - 2s 621ms/step - loss: 0.9797 - accuracy: 0.6667 - val_loss: 0.3865 - val_accuracy: 0.8646\n",
            "Epoch 9/150\n",
            "3/3 [==============================] - 2s 665ms/step - loss: 0.9751 - accuracy: 0.7000 - val_loss: 0.3787 - val_accuracy: 0.8438\n",
            "Epoch 10/150\n",
            "3/3 [==============================] - 2s 738ms/step - loss: 0.8984 - accuracy: 0.7333 - val_loss: 0.3049 - val_accuracy: 0.9062\n",
            "Epoch 11/150\n",
            "3/3 [==============================] - 2s 863ms/step - loss: 0.8810 - accuracy: 0.6889 - val_loss: 0.2915 - val_accuracy: 0.8958\n",
            "Epoch 12/150\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.6684 - accuracy: 0.8000 - val_loss: 0.2330 - val_accuracy: 0.9375\n",
            "Epoch 13/150\n",
            "3/3 [==============================] - 2s 667ms/step - loss: 0.7470 - accuracy: 0.7556 - val_loss: 0.2202 - val_accuracy: 0.9271\n",
            "Epoch 14/150\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 0.6509 - accuracy: 0.7556 - val_loss: 0.1982 - val_accuracy: 0.9271\n",
            "Epoch 15/150\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.7665 - accuracy: 0.7111 - val_loss: 0.2169 - val_accuracy: 0.9271\n",
            "Epoch 16/150\n",
            "3/3 [==============================] - 2s 626ms/step - loss: 0.6746 - accuracy: 0.7778 - val_loss: 0.1776 - val_accuracy: 0.9375\n",
            "Epoch 17/150\n",
            "3/3 [==============================] - 3s 908ms/step - loss: 0.6021 - accuracy: 0.8125 - val_loss: 0.1874 - val_accuracy: 0.9479\n",
            "Epoch 18/150\n",
            "3/3 [==============================] - 2s 539ms/step - loss: 0.5635 - accuracy: 0.8222 - val_loss: 0.1770 - val_accuracy: 0.9583\n",
            "Epoch 19/150\n",
            "3/3 [==============================] - 2s 701ms/step - loss: 0.5733 - accuracy: 0.7708 - val_loss: 0.1671 - val_accuracy: 0.9583\n",
            "Epoch 20/150\n",
            "3/3 [==============================] - 2s 624ms/step - loss: 0.5947 - accuracy: 0.8438 - val_loss: 0.1637 - val_accuracy: 0.9271\n",
            "Epoch 21/150\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.6185 - accuracy: 0.8000 - val_loss: 0.1405 - val_accuracy: 0.9375\n",
            "Epoch 22/150\n",
            "3/3 [==============================] - 2s 910ms/step - loss: 0.4931 - accuracy: 0.8646 - val_loss: 0.1278 - val_accuracy: 0.9688\n",
            "Epoch 23/150\n",
            "3/3 [==============================] - 2s 714ms/step - loss: 0.4765 - accuracy: 0.8125 - val_loss: 0.1201 - val_accuracy: 0.9583\n",
            "Epoch 24/150\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 0.5367 - accuracy: 0.8333 - val_loss: 0.1215 - val_accuracy: 0.9479\n",
            "Epoch 25/150\n",
            "3/3 [==============================] - 2s 711ms/step - loss: 0.5095 - accuracy: 0.8333 - val_loss: 0.1269 - val_accuracy: 0.9479\n",
            "Epoch 26/150\n",
            "3/3 [==============================] - 2s 656ms/step - loss: 0.3925 - accuracy: 0.8778 - val_loss: 0.1302 - val_accuracy: 0.9479\n",
            "Epoch 27/150\n",
            "3/3 [==============================] - 3s 966ms/step - loss: 0.3475 - accuracy: 0.9062 - val_loss: 0.1583 - val_accuracy: 0.9167\n",
            "Epoch 28/150\n",
            "3/3 [==============================] - 2s 635ms/step - loss: 0.3737 - accuracy: 0.8667 - val_loss: 0.1130 - val_accuracy: 0.9479\n",
            "Epoch 29/150\n",
            "3/3 [==============================] - 2s 711ms/step - loss: 0.3722 - accuracy: 0.8854 - val_loss: 0.1353 - val_accuracy: 0.9271\n",
            "Epoch 30/150\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.4423 - accuracy: 0.8556 - val_loss: 0.0834 - val_accuracy: 0.9688\n",
            "Epoch 31/150\n",
            "3/3 [==============================] - 2s 903ms/step - loss: 0.3894 - accuracy: 0.8889 - val_loss: 0.0890 - val_accuracy: 0.9896\n",
            "Epoch 32/150\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.5093 - accuracy: 0.8333 - val_loss: 0.0702 - val_accuracy: 0.9896\n",
            "Epoch 33/150\n",
            "3/3 [==============================] - 2s 671ms/step - loss: 0.3265 - accuracy: 0.8778 - val_loss: 0.0925 - val_accuracy: 0.9479\n",
            "Epoch 34/150\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.3703 - accuracy: 0.8750 - val_loss: 0.0893 - val_accuracy: 0.9583\n",
            "Epoch 35/150\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 0.3377 - accuracy: 0.8646 - val_loss: 0.0899 - val_accuracy: 0.9479\n",
            "Epoch 36/150\n",
            "3/3 [==============================] - 2s 683ms/step - loss: 0.3524 - accuracy: 0.8889 - val_loss: 0.0812 - val_accuracy: 0.9583\n",
            "Epoch 37/150\n",
            "3/3 [==============================] - 2s 617ms/step - loss: 0.2769 - accuracy: 0.9062 - val_loss: 0.0723 - val_accuracy: 0.9896\n",
            "Epoch 38/150\n",
            "3/3 [==============================] - 2s 929ms/step - loss: 0.3006 - accuracy: 0.8889 - val_loss: 0.0711 - val_accuracy: 0.9792\n",
            "Epoch 39/150\n",
            "3/3 [==============================] - 2s 574ms/step - loss: 0.2879 - accuracy: 0.9111 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
            "Epoch 40/150\n",
            "3/3 [==============================] - 2s 625ms/step - loss: 0.3986 - accuracy: 0.8646 - val_loss: 0.0772 - val_accuracy: 0.9792\n",
            "Epoch 41/150\n",
            "3/3 [==============================] - 2s 601ms/step - loss: 0.3070 - accuracy: 0.8854 - val_loss: 0.0727 - val_accuracy: 0.9792\n",
            "Epoch 42/150\n",
            "3/3 [==============================] - 2s 613ms/step - loss: 0.2536 - accuracy: 0.9375 - val_loss: 0.0618 - val_accuracy: 0.9896\n",
            "Epoch 43/150\n",
            "3/3 [==============================] - 2s 677ms/step - loss: 0.2150 - accuracy: 0.9556 - val_loss: 0.0763 - val_accuracy: 0.9792\n",
            "Epoch 44/150\n",
            "3/3 [==============================] - 2s 868ms/step - loss: 0.3190 - accuracy: 0.8889 - val_loss: 0.0534 - val_accuracy: 0.9896\n",
            "Epoch 45/150\n",
            "3/3 [==============================] - 2s 792ms/step - loss: 0.2070 - accuracy: 0.9479 - val_loss: 0.0689 - val_accuracy: 0.9688\n",
            "Epoch 46/150\n",
            "3/3 [==============================] - 2s 718ms/step - loss: 0.2435 - accuracy: 0.9222 - val_loss: 0.0577 - val_accuracy: 0.9792\n",
            "Epoch 47/150\n",
            "3/3 [==============================] - 2s 676ms/step - loss: 0.3299 - accuracy: 0.8778 - val_loss: 0.0497 - val_accuracy: 0.9896\n",
            "Epoch 48/150\n",
            "3/3 [==============================] - 2s 630ms/step - loss: 0.2337 - accuracy: 0.9271 - val_loss: 0.0442 - val_accuracy: 0.9896\n",
            "Epoch 49/150\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.2282 - accuracy: 0.8889 - val_loss: 0.0555 - val_accuracy: 0.9896\n",
            "Epoch 50/150\n",
            "3/3 [==============================] - 2s 839ms/step - loss: 0.2639 - accuracy: 0.8778 - val_loss: 0.0582 - val_accuracy: 0.9792\n",
            "Epoch 51/150\n",
            "3/3 [==============================] - 2s 864ms/step - loss: 0.2222 - accuracy: 0.8958 - val_loss: 0.0703 - val_accuracy: 0.9896\n",
            "Epoch 52/150\n",
            "3/3 [==============================] - 2s 592ms/step - loss: 0.1841 - accuracy: 0.9556 - val_loss: 0.0599 - val_accuracy: 0.9896\n",
            "Epoch 53/150\n",
            "3/3 [==============================] - 2s 699ms/step - loss: 0.1950 - accuracy: 0.9271 - val_loss: 0.0581 - val_accuracy: 0.9583\n",
            "Epoch 54/150\n",
            "3/3 [==============================] - 2s 616ms/step - loss: 0.2619 - accuracy: 0.9167 - val_loss: 0.0656 - val_accuracy: 0.9583\n",
            "Epoch 55/150\n",
            "3/3 [==============================] - 2s 633ms/step - loss: 0.2663 - accuracy: 0.9444 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "3/3 [==============================] - 3s 868ms/step - loss: 0.1960 - accuracy: 0.9444 - val_loss: 0.0544 - val_accuracy: 0.9896\n",
            "Epoch 57/150\n",
            "3/3 [==============================] - 2s 733ms/step - loss: 0.2205 - accuracy: 0.9111 - val_loss: 0.0602 - val_accuracy: 0.9792\n",
            "Epoch 58/150\n",
            "3/3 [==============================] - 2s 611ms/step - loss: 0.2073 - accuracy: 0.9333 - val_loss: 0.0612 - val_accuracy: 0.9583\n",
            "Epoch 59/150\n",
            "3/3 [==============================] - 2s 673ms/step - loss: 0.2125 - accuracy: 0.9222 - val_loss: 0.0470 - val_accuracy: 0.9792\n",
            "Epoch 60/150\n",
            "3/3 [==============================] - 2s 631ms/step - loss: 0.1778 - accuracy: 0.9375 - val_loss: 0.0594 - val_accuracy: 0.9792\n",
            "Epoch 61/150\n",
            "3/3 [==============================] - 2s 619ms/step - loss: 0.1974 - accuracy: 0.9062 - val_loss: 0.0613 - val_accuracy: 0.9583\n",
            "Epoch 62/150\n",
            "3/3 [==============================] - 2s 663ms/step - loss: 0.1734 - accuracy: 0.9444 - val_loss: 0.0459 - val_accuracy: 0.9896\n",
            "Epoch 63/150\n",
            "3/3 [==============================] - 2s 701ms/step - loss: 0.1844 - accuracy: 0.9375 - val_loss: 0.0561 - val_accuracy: 0.9896\n",
            "Epoch 64/150\n",
            "3/3 [==============================] - 2s 716ms/step - loss: 0.2728 - accuracy: 0.8778 - val_loss: 0.0726 - val_accuracy: 0.9583\n",
            "Epoch 65/150\n",
            "3/3 [==============================] - 2s 578ms/step - loss: 0.1672 - accuracy: 0.9667 - val_loss: 0.1181 - val_accuracy: 0.9375\n",
            "Epoch 66/150\n",
            "3/3 [==============================] - 2s 618ms/step - loss: 0.2291 - accuracy: 0.9167 - val_loss: 0.0852 - val_accuracy: 0.9479\n",
            "Epoch 67/150\n",
            "3/3 [==============================] - 2s 627ms/step - loss: 0.0939 - accuracy: 0.9688 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "3/3 [==============================] - 2s 767ms/step - loss: 0.1947 - accuracy: 0.9333 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 0.0413 - val_accuracy: 0.9896\n",
            "Epoch 70/150\n",
            "3/3 [==============================] - 2s 662ms/step - loss: 0.1886 - accuracy: 0.9333 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "3/3 [==============================] - 2s 707ms/step - loss: 0.1645 - accuracy: 0.9556 - val_loss: 0.0343 - val_accuracy: 0.9896\n",
            "Epoch 72/150\n",
            "3/3 [==============================] - 2s 724ms/step - loss: 0.2303 - accuracy: 0.9000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "3/3 [==============================] - 2s 717ms/step - loss: 0.1842 - accuracy: 0.9222 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "3/3 [==============================] - 2s 880ms/step - loss: 0.1931 - accuracy: 0.9222 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "3/3 [==============================] - 2s 658ms/step - loss: 0.1701 - accuracy: 0.9444 - val_loss: 0.0462 - val_accuracy: 0.9688\n",
            "Epoch 76/150\n",
            "3/3 [==============================] - 2s 669ms/step - loss: 0.1955 - accuracy: 0.9556 - val_loss: 0.0321 - val_accuracy: 0.9896\n",
            "Epoch 77/150\n",
            "3/3 [==============================] - 2s 665ms/step - loss: 0.2062 - accuracy: 0.9444 - val_loss: 0.0406 - val_accuracy: 0.9792\n",
            "Epoch 78/150\n",
            "3/3 [==============================] - 2s 580ms/step - loss: 0.1627 - accuracy: 0.9444 - val_loss: 0.0384 - val_accuracy: 0.9792\n",
            "Epoch 79/150\n",
            "3/3 [==============================] - 2s 598ms/step - loss: 0.1606 - accuracy: 0.9333 - val_loss: 0.0360 - val_accuracy: 0.9896\n",
            "Epoch 80/150\n",
            "3/3 [==============================] - 2s 877ms/step - loss: 0.2657 - accuracy: 0.9000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "3/3 [==============================] - 2s 717ms/step - loss: 0.1079 - accuracy: 0.9889 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "3/3 [==============================] - 2s 724ms/step - loss: 0.1560 - accuracy: 0.9479 - val_loss: 0.0312 - val_accuracy: 0.9896\n",
            "Epoch 83/150\n",
            "3/3 [==============================] - 2s 733ms/step - loss: 0.1826 - accuracy: 0.9167 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "3/3 [==============================] - 2s 666ms/step - loss: 0.1744 - accuracy: 0.9333 - val_loss: 0.0486 - val_accuracy: 0.9792\n",
            "Epoch 85/150\n",
            "3/3 [==============================] - 2s 624ms/step - loss: 0.2301 - accuracy: 0.9222 - val_loss: 0.0363 - val_accuracy: 0.9896\n",
            "Epoch 86/150\n",
            "3/3 [==============================] - 2s 917ms/step - loss: 0.2563 - accuracy: 0.8889 - val_loss: 0.0301 - val_accuracy: 0.9896\n",
            "Epoch 87/150\n",
            "3/3 [==============================] - 2s 679ms/step - loss: 0.2010 - accuracy: 0.9271 - val_loss: 0.0299 - val_accuracy: 0.9896\n",
            "Epoch 88/150\n",
            "3/3 [==============================] - 2s 615ms/step - loss: 0.2077 - accuracy: 0.9167 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "3/3 [==============================] - 2s 667ms/step - loss: 0.1439 - accuracy: 0.9667 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "3/3 [==============================] - 2s 713ms/step - loss: 0.1539 - accuracy: 0.9375 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "3/3 [==============================] - 2s 627ms/step - loss: 0.1334 - accuracy: 0.9479 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "3/3 [==============================] - 2s 916ms/step - loss: 0.2614 - accuracy: 0.9062 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "3/3 [==============================] - 2s 679ms/step - loss: 0.1521 - accuracy: 0.9444 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "3/3 [==============================] - 2s 667ms/step - loss: 0.1607 - accuracy: 0.9556 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "3/3 [==============================] - 2s 706ms/step - loss: 0.1672 - accuracy: 0.9333 - val_loss: 0.0369 - val_accuracy: 0.9792\n",
            "Epoch 96/150\n",
            "3/3 [==============================] - 2s 674ms/step - loss: 0.2032 - accuracy: 0.9556 - val_loss: 0.0275 - val_accuracy: 0.9896\n",
            "Epoch 97/150\n",
            "3/3 [==============================] - 2s 669ms/step - loss: 0.1348 - accuracy: 0.9556 - val_loss: 0.0299 - val_accuracy: 0.9792\n",
            "Epoch 98/150\n",
            "3/3 [==============================] - 3s 924ms/step - loss: 0.1347 - accuracy: 0.9479 - val_loss: 0.0302 - val_accuracy: 0.9896\n",
            "Epoch 99/150\n",
            "3/3 [==============================] - 2s 673ms/step - loss: 0.2005 - accuracy: 0.9333 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "3/3 [==============================] - 2s 673ms/step - loss: 0.1101 - accuracy: 0.9667 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "3/3 [==============================] - 2s 608ms/step - loss: 0.0949 - accuracy: 0.9896 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "3/3 [==============================] - 2s 715ms/step - loss: 0.1036 - accuracy: 0.9667 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "3/3 [==============================] - 2s 617ms/step - loss: 0.1246 - accuracy: 0.9583 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "3/3 [==============================] - 2s 932ms/step - loss: 0.1783 - accuracy: 0.9333 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "3/3 [==============================] - 2s 703ms/step - loss: 0.1565 - accuracy: 0.9444 - val_loss: 0.0411 - val_accuracy: 0.9792\n",
            "Epoch 106/150\n",
            "3/3 [==============================] - 2s 615ms/step - loss: 0.1617 - accuracy: 0.9479 - val_loss: 0.0304 - val_accuracy: 0.9896\n",
            "Epoch 107/150\n",
            "3/3 [==============================] - 2s 567ms/step - loss: 0.1301 - accuracy: 0.9778 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "3/3 [==============================] - 2s 581ms/step - loss: 0.1098 - accuracy: 0.9667 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "3/3 [==============================] - 2s 685ms/step - loss: 0.1478 - accuracy: 0.9444 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "3/3 [==============================] - 2s 711ms/step - loss: 0.1673 - accuracy: 0.9333 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "3/3 [==============================] - 2s 962ms/step - loss: 0.2265 - accuracy: 0.9222 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "3/3 [==============================] - 2s 723ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "3/3 [==============================] - 2s 580ms/step - loss: 0.0907 - accuracy: 0.9889 - val_loss: 0.0320 - val_accuracy: 0.9688\n",
            "Epoch 114/150\n",
            "3/3 [==============================] - 2s 675ms/step - loss: 0.1890 - accuracy: 0.9333 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "3/3 [==============================] - 2s 684ms/step - loss: 0.1075 - accuracy: 0.9667 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.1977 - accuracy: 0.9375 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "3/3 [==============================] - 2s 850ms/step - loss: 0.1346 - accuracy: 0.9556 - val_loss: 0.0253 - val_accuracy: 0.9896\n",
            "Epoch 118/150\n",
            "3/3 [==============================] - 2s 684ms/step - loss: 0.1276 - accuracy: 0.9444 - val_loss: 0.0648 - val_accuracy: 0.9583\n",
            "Epoch 119/150\n",
            "3/3 [==============================] - 2s 588ms/step - loss: 0.1936 - accuracy: 0.9000 - val_loss: 0.0330 - val_accuracy: 0.9896\n",
            "Epoch 120/150\n",
            "3/3 [==============================] - 2s 721ms/step - loss: 0.1602 - accuracy: 0.9271 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "3/3 [==============================] - 2s 587ms/step - loss: 0.1308 - accuracy: 0.9556 - val_loss: 0.0371 - val_accuracy: 0.9896\n",
            "Epoch 122/150\n",
            "3/3 [==============================] - 2s 727ms/step - loss: 0.1802 - accuracy: 0.9479 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "3/3 [==============================] - 2s 823ms/step - loss: 0.1043 - accuracy: 0.9667 - val_loss: 0.0317 - val_accuracy: 0.9792\n",
            "Epoch 124/150\n",
            "3/3 [==============================] - 2s 680ms/step - loss: 0.2106 - accuracy: 0.9111 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "3/3 [==============================] - 2s 580ms/step - loss: 0.1202 - accuracy: 0.9556 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "3/3 [==============================] - 2s 672ms/step - loss: 0.1624 - accuracy: 0.9444 - val_loss: 0.0254 - val_accuracy: 0.9896\n",
            "Epoch 127/150\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.1203 - accuracy: 0.9556 - val_loss: 0.0194 - val_accuracy: 0.9896\n",
            "Epoch 128/150\n",
            "3/3 [==============================] - 2s 724ms/step - loss: 0.2127 - accuracy: 0.9333 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "3/3 [==============================] - 3s 912ms/step - loss: 0.1433 - accuracy: 0.9556 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "3/3 [==============================] - 2s 639ms/step - loss: 0.1210 - accuracy: 0.9444 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.1327 - accuracy: 0.9444 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "3/3 [==============================] - 2s 682ms/step - loss: 0.1521 - accuracy: 0.9667 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "3/3 [==============================] - 2s 706ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "3/3 [==============================] - 2s 614ms/step - loss: 0.1627 - accuracy: 0.9375 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "3/3 [==============================] - 2s 872ms/step - loss: 0.1075 - accuracy: 0.9667 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "3/3 [==============================] - 2s 688ms/step - loss: 0.1094 - accuracy: 0.9583 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "3/3 [==============================] - 2s 586ms/step - loss: 0.1077 - accuracy: 0.9667 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "3/3 [==============================] - 2s 625ms/step - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.0378 - val_accuracy: 0.9896\n",
            "Epoch 139/150\n",
            "3/3 [==============================] - 2s 581ms/step - loss: 0.1541 - accuracy: 0.9333 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "3/3 [==============================] - 2s 702ms/step - loss: 0.1464 - accuracy: 0.9271 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "3/3 [==============================] - 2s 665ms/step - loss: 0.1403 - accuracy: 0.9583 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "3/3 [==============================] - 3s 885ms/step - loss: 0.1227 - accuracy: 0.9444 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "3/3 [==============================] - 2s 632ms/step - loss: 0.1579 - accuracy: 0.9556 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "3/3 [==============================] - 2s 626ms/step - loss: 0.1921 - accuracy: 0.9375 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "3/3 [==============================] - 2s 682ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9896\n",
            "Epoch 146/150\n",
            "3/3 [==============================] - 2s 674ms/step - loss: 0.1077 - accuracy: 0.9556 - val_loss: 0.0157 - val_accuracy: 0.9896\n",
            "Epoch 147/150\n",
            "3/3 [==============================] - 2s 726ms/step - loss: 0.1009 - accuracy: 0.9688 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "3/3 [==============================] - 2s 899ms/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "3/3 [==============================] - 2s 682ms/step - loss: 0.0966 - accuracy: 0.9667 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "3/3 [==============================] - 2s 714ms/step - loss: 0.0741 - accuracy: 0.9778 - val_loss: 0.0068 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size,\n",
        "    epochs=150\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model.save('furniture.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8JYDr0d82aY",
        "outputId": "8a7ae886-be1c-479f-ecff-4eb98469b182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], Class name: meja01\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Dictionary mapping kelas ke nama furniture\n",
        "class_indices = train_generator.class_indices\n",
        "index_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    class_index = np.argmax(prediction)\n",
        "    class_name = index_to_class[class_index]\n",
        "    one_hot_encoded = np.zeros(14)\n",
        "    one_hot_encoded[class_index] = 1\n",
        "\n",
        "    return one_hot_encoded, class_name\n",
        "\n",
        "# Penggunaan function predict_image\n",
        "img_path = '/train/meja01/meja134.JPG'\n",
        "one_hot, class_name = predict_image(img_path)\n",
        "print(f\"Predicted one-hot: {one_hot}, Class name: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obac3b5taLHB",
        "outputId": "5e347d96-f545-43c4-f79a-3a1cd90a9b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 212ms/step\n",
            "Predicted one-hot: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Class name: kursi04\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model('/furniture.h5')\n",
        "\n",
        "# Function untuk prediksi\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = loaded_model.predict(img_array)\n",
        "    class_index = np.argmax(prediction)\n",
        "    class_name = index_to_class[class_index]\n",
        "    one_hot_encoded = np.zeros(14)\n",
        "    one_hot_encoded[class_index] = 1\n",
        "\n",
        "    return one_hot_encoded, class_name\n",
        "\n",
        "# Penggunaan function predict_image\n",
        "img_path = '/train/kursi04/kursi413.JPG'\n",
        "one_hot, class_name = predict_image(img_path)\n",
        "print(f\"Predicted one-hot: {one_hot}, Class name: {class_name}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
